{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "properties": {
    "model": {
      "type": "string",
      "description": "The model that will complete your prompt.",
      "minLength": 1,
      "maxLength": 256
    },
    "messages": {
      "type": "array",
      "description": "Input messages. Our models are trained to operate on alternating user and assistant conversational turns. When creating a new Message, you specify the prior conversational turns with the messages parameter, and the model then generates the next Message in the conversation. Consecutive user or assistant turns in your request will be combined into a single turn. Each input message must be an object with a role and content. You can specify a single user-role message, or you can include multiple user and assistant messages. If the final message uses the assistant role, the response content will continue immediately from the content in that message. There is a limit of 100,000 messages in a single request.",
      "items": {
        "type": "object",
        "properties": {
          "role": {
            "type": "string",
            "description": "The conversational role of the message. Must be either 'user' or 'assistant'."
          },
          "content": {
            "oneOf": [
              {
                "type": "string",
                "description": "The content of the message as a string (shorthand for an array of one content block of type 'text')."
              },
              {
                "type": "array",
                "description": "The content of the message as an array of content blocks, where each block has a specific type.",
                "items": {
                  "type": "object",
                  "properties": {
                    "type": {
                      "type": "string",
                      "description": "The type of content block."
                    },
                    "text": {
                      "type": "string",
                      "description": "The text content of the message block. Present when type is 'text'."
                    }
                  }
                }
              }
            ]
          }
        },
        "required": ["role", "content"]
      }
    },
    "system": {
      "oneOf": [
        {
          "type": "string",
          "description": "System prompt as a string. A system prompt is a way of providing context and instructions to Claude, such as specifying a particular goal or role."
        },
        {
          "type": "array",
          "description": "System prompt as an array of text blocks.",
          "items": {
            "type": "object",
            "properties": {
              "type": {
                "type": "string",
                "enum": ["text"]
              },
              "text": {
                "type": "string",
                "description": "The text content of the system prompt block."
              }
            },
            "required": ["type", "text"]
          }
        }
      ]
    },
    "tools": {
      "type": "array",
      "description": "Definitions of tools that the model may use. If you include tools in your API request, the model may return tool_use content blocks that represent the model's use of those tools. You can then run those tools using the tool input generated by the model and then optionally return results back to the model using tool_result content blocks. Each tool definition includes: name (Name of the tool), description (Optional, but strongly-recommended description of the tool), input_schema (JSON schema for the tool input shape that the model will produce in tool_use output content blocks).",
      "items": {
        "type": "object",
        "properties": {
          "name": {
            "type": "string",
            "description": "Name of the tool."
          },
          "description": {
            "type": "string",
            "description": "Optional, but strongly-recommended description of the tool."
          },
          "input_schema": {
            "description": "JSON Schema for the tool input. Can be a URL to a JSON Schema or an inline schema object.",
            "oneOf": [
              {
                "type": "string",
                "description": "URL to a JSON Schema definition"
              },
              {
                "type": "object",
                "description": "Inline JSON Schema object"
              }
            ]
          }
        },
        "required": ["name", "input_schema"]
      }
    },
    "tool_choice": {
      "type": "object",
      "description": "How the model should use the provided tools. The model can use a specific tool, any available tool, decide by itself, or not use tools at all. The model will automatically decide whether to use tools.",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["auto", "any", "tool", "none"],
          "description": "The tool choice strategy: 'auto' (model decides), 'any' (must use at least one tool), 'tool' (must use specific tool), or 'none' (no tools)."
        },
        "name": {
          "type": "string",
          "description": "The name of the tool to force the model to use. Required when type is 'tool'."
        }
      },
      "required": ["type"]
    },
    "thinking": {
      "type": "object",
      "description": "Configuration for enabling Claude's extended thinking. When enabled, responses include thinking content blocks showing Claude's thinking process before the final answer. Requires a minimum budget of 1,024 tokens and counts towards your max_tokens limit.",
      "properties": {
        "type": {
          "type": "string",
          "description": "The type of thinking mode to enable."
        },
        "budget_tokens": {
          "type": "number",
          "minimum": 1024,
          "description": "The maximum number of tokens to allocate for thinking. Minimum value is 1024."
        }
      },
      "required": ["type"]
    },
    "context_management": {
      "type": ["object", "null"],
      "description": "Context management configuration. This allows you to control how Claude manages context across multiple requests, such as whether to clear function results or not."
    },
    "mcp_servers": {
      "type": "array",
      "description": "MCP servers to be utilized in this request. Maximum of 20 servers.",
      "maxItems": 20,
      "items": {
        "type": "object",
        "properties": {
          "name": {
            "type": "string",
            "description": "The name of the MCP server."
          },
          "type": {
            "type": "string",
            "description": "The type of MCP server."
          },
          "url": {
            "type": "string",
            "description": "The URL of the MCP server."
          },
          "authorization_token": {
            "type": "string",
            "description": "The authorization token for the MCP server."
          },
          "tool_configuration": {
            "type": "object",
            "description": "Configuration for tools available from this MCP server.",
            "properties": {
              "allowed_tools": {
                "type": "array",
                "description": "Array of tool names that are allowed to be used from this server.",
                "items": {
                  "type": "string"
                }
              },
              "enabled": {
                "type": "boolean",
                "description": "Whether tools from this server are enabled."
              }
            }
          }
        },
        "required": ["name", "type", "url"]
      }
    }
  },
  "required": ["model", "messages"]
}
